{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPehsidtYAZuWQzMyUik8Yb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AldoFerreira17/Rede_Neural_MLP_Autoencoder/blob/main/Rede_neural_MLP_e_autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importação das Bibliotecas\n",
        "\n",
        "Nesta célula, importamos as bibliotecas necessárias. Isso inclui TensorFlow/Keras para construir o modelo, Matplotlib para visualização e IPython para exibir as imagens dinamicamente no Colab."
      ],
      "metadata": {
        "id": "Gfu9V80eH_JC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bA4p-DyeH-Rr"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.layers import Dense, Input, Flatten, Reshape, LeakyReLU as LR, Activation, Dropout\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from matplotlib import pyplot as plt\n",
        "from IPython import display\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carregamento e Normalização dos Dados\n",
        "\n",
        "Carregamos o conjunto de dados MNIST, que contém imagens de dígitos escritos à mão. Em seguida, normalizamos os dados dividindo cada valor por 255 para que os valores dos pixels fiquem entre 0 e 1."
      ],
      "metadata": {
        "id": "M4zOYjLlIQa6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0"
      ],
      "metadata": {
        "id": "hFwwpuFkIakh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualização de um Exemplo de Imagem\n",
        "\n",
        "Mostramos uma imagem do conjunto de treinamento para visualizar os dados com os quais estamos trabalhando. Esta célula ajuda a confirmar que os dados foram carregados corretamente."
      ],
      "metadata": {
        "id": "Fejr7px0JSD5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(x_train[0], cmap = \"gray\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "16hurPdWJY09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definição do Codificador (Encoder)\n",
        "\n",
        "Definimos o codificador, que é a parte do modelo responsável por comprimir as imagens em um vetor latente de dimensão menor (LATENT_SIZE). Ele usa camadas densas (fully connected) com Leaky ReLU e dropout para prevenir overfitting."
      ],
      "metadata": {
        "id": "V-H3Te1pJhd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LATENT_SIZE = 32\n",
        "encoder = Sequential([\n",
        "    Flatten(input_shape = (28, 28)),\n",
        "    Dense(512),\n",
        "    LR(),\n",
        "    Dropout(0.5),\n",
        "    Dense(256),\n",
        "    LR(),\n",
        "    Dropout(0.5),\n",
        "    Dense(128),\n",
        "    LR(),\n",
        "    Dropout(0.5),\n",
        "    Dense(64),\n",
        "    LR(),\n",
        "    Dropout(0.5),\n",
        "    Dense(LATENT_SIZE),\n",
        "    LR()\n",
        "])"
      ],
      "metadata": {
        "id": "4_Ra98sHJhx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definição do Decodificador (Decoder)\n",
        "\n",
        "Definimos o decodificador, que reconstrói as imagens a partir do vetor latente. Ele usa a mesma arquitetura com camadas densas e Leaky ReLU, mas termina com uma ativação sigmoide e uma camada de reshaping para transformar o vetor de volta em uma imagem 28x28.\n"
      ],
      "metadata": {
        "id": "JTmunB5cJx6B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decoder = Sequential([\n",
        "    Dense(64, input_shape = (LATENT_SIZE,)),\n",
        "    LR(),\n",
        "    Dropout(0.5),\n",
        "    Dense(128),\n",
        "    LR(),\n",
        "    Dropout(0.5),\n",
        "    Dense(256),\n",
        "    LR(),\n",
        "    Dropout(0.5),\n",
        "    Dense(512),\n",
        "    LR(),\n",
        "    Dropout(0.5),\n",
        "    Dense(784),\n",
        "    Activation(\"sigmoid\"),\n",
        "    Reshape((28, 28))\n",
        "])"
      ],
      "metadata": {
        "id": "EnQE0GMRJyPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definição e Compilação do Modelo\n",
        "\n",
        "Conectamos o codificador e o decodificador em um modelo completo. A imagem de entrada é codificada no vetor latente e, em seguida, reconstruída. O modelo é compilado com o otimizador Nadam e a função de perda binary_crossentropy."
      ],
      "metadata": {
        "id": "Sq3p_4LdKC18"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = Input(shape = (28, 28))\n",
        "latent_vector = encoder(img)\n",
        "output = decoder(latent_vector)\n",
        "model = Model(inputs = img, outputs = output)\n",
        "model.compile(\"nadam\", loss = \"binary_crossentropy\")"
      ],
      "metadata": {
        "id": "DGn90GcbKDBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Treinamento do Modelo com Visualização das Saídas\n",
        "\n",
        "O modelo é treinado por várias épocas (EPOCHS). A cada época, o modelo gera uma visualização de imagens reconstruídas a partir do conjunto de teste, para monitorar visualmente o progresso do treinamento. Em seguida, ele treina com os dados de treinamento."
      ],
      "metadata": {
        "id": "Z4gVJ83UKQex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 60\n",
        "for epoch in range(EPOCHS):\n",
        "    fig, axs = plt.subplots(4, 4)\n",
        "    rand = x_test[np.random.randint(0, 10000, 16)].reshape((4, 4, 1, 28, 28))\n",
        "\n",
        "    display.clear_output()\n",
        "\n",
        "    for i in range(4):\n",
        "        for j in range(4):\n",
        "            axs[i, j].imshow(model.predict(rand[i, j])[0], cmap = \"gray\")\n",
        "            axs[i, j].axis(\"off\")\n",
        "\n",
        "    plt.subplots_adjust(wspace = 0, hspace = 0)\n",
        "    plt.show()\n",
        "    print(\"-----------\", \"EPOCH\", epoch, \"-----------\")\n",
        "    model.fit(x_train, x_train)"
      ],
      "metadata": {
        "id": "pv74mHisKRW5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}